{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b41f3b",
   "metadata": {},
   "source": [
    "Mayank Raj\n",
    "22BAI1118"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f78285",
   "metadata": {},
   "source": [
    "# PERCEPTRON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "761f7b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from matplotlib.colors import ListedColormap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082b85f7",
   "metadata": {},
   "source": [
    "### Inference \n",
    "This cell sets up the necessary libraries for data manipulation, numerical computations, visualization, and model serialization. These libraries are essential for handling data, building models, and visualizing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3a055d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, eta: float=None, epochs: int=None, val: int=None):\n",
    "        # Initialize the Perceptron with learning rate (eta), number of epochs, and number of inputs (val)\n",
    "        self.val = val\n",
    "        # Initialize weights with small random values\n",
    "        self.weights = np.random.randn(val) * 1e-4  \n",
    "        training = (eta is not None) and (epochs is not None)\n",
    "        if training:\n",
    "            print(f\"Initial weights before training: \\n{self.weights}\\n\")\n",
    "        self.eta = eta  # Learning rate\n",
    "        self.epochs = epochs  # Number of training epochs\n",
    "    \n",
    "    def _z_outcome(self, inputs, weights):\n",
    "        # Calculate the linear combination of inputs and weights\n",
    "        return np.dot(inputs, weights)\n",
    "    \n",
    "    def activation_function(self, z):\n",
    "        # Apply the step function to the linear combination to get the binary output\n",
    "        return np.where(z > 0, 1, 0)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Train the Perceptron model\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # Add bias term to the input data\n",
    "        X_with_bias = np.c_[self.X, -np.ones((len(self.X), 1))]\n",
    "        print(f\"X with bias: \\n{X_with_bias}\")\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            print(\"--\"*10)\n",
    "            print(f\"Epoch {epoch}\")\n",
    "            print(\"--\"*10)\n",
    "            \n",
    "            # Compute the linear combination\n",
    "            z = self._z_outcome(X_with_bias, self.weights)\n",
    "            # Get the predicted output\n",
    "            y_hat = self.activation_function(z)\n",
    "            \n",
    "            # Compute the error\n",
    "            self.error = self.y - y_hat\n",
    "            \n",
    "            # Update weights using the Perceptron learning rule\n",
    "            self.weights += self.eta * np.dot(X_with_bias.T, self.error)\n",
    "            print(f\"Updated weights after epoch {epoch + 1}/{self.epochs}: \\n{self.weights}\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Predict the output for given input data\n",
    "        X_with_bias = np.c_[X, -np.ones((len(X), 1))]  # Add bias term\n",
    "        z = self._z_outcome(X_with_bias, self.weights)\n",
    "        return self.activation_function(z)\n",
    "    \n",
    "    def total_loss(self):\n",
    "        # Calculate and print the total loss (sum of errors)\n",
    "        total_loss = np.sum(self.error)\n",
    "        print(f\"\\nTotal loss: {total_loss}\\n\")\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9f1ff3",
   "metadata": {},
   "source": [
    "### Inference\n",
    "This cell defines the Perceptron class, including methods for initialization, training, prediction, and model management. The fit method trains the model by updating weights based on the errors computed from predictions. The predict method generates outputs for new data, and the save and load methods handle model persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9b4c852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, target_col=\"y\"):\n",
    "    # Drop the target column to get the features (X)\n",
    "    X = df.drop(target_col, axis=1)\n",
    "    \n",
    "    # Extract the target column (y)\n",
    "    y = df[target_col]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c74051",
   "metadata": {},
   "source": [
    "### Inference\n",
    "This function splits a DataFrame into features (X) and target labels (y) based on the specified target column. It prepares the data for training or evaluation by separating input features from the output labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82f398a",
   "metadata": {},
   "source": [
    "# -> 2 Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aaaede",
   "metadata": {},
   "source": [
    "## AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ffa976b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1  x2  y\n",
      "0   0   0  0\n",
      "1   0   1  0\n",
      "2   1   0  0\n",
      "3   1   1  1 \n",
      "\n",
      "Initial weights before training: \n",
      "[ 1.49786463e-04 -1.97290300e-04  3.47732404e-05]\n",
      "\n",
      "X with bias: \n",
      "[[ 0.  0. -1.]\n",
      " [ 0.  1. -1.]\n",
      " [ 1.  0. -1.]\n",
      " [ 1.  1. -1.]]\n",
      "--------------------\n",
      "Epoch 0\n",
      "--------------------\n",
      "Updated weights after epoch 1/10: \n",
      "[1.49786463e-04 9.98027097e-02 3.47732404e-05]\n",
      "--------------------\n",
      "Epoch 1\n",
      "--------------------\n",
      "Updated weights after epoch 2/10: \n",
      "[-9.98502135e-02 -1.97290300e-04  2.00034773e-01]\n",
      "--------------------\n",
      "Epoch 2\n",
      "--------------------\n",
      "Updated weights after epoch 3/10: \n",
      "[0.00014979 0.09980271 0.10003477]\n",
      "--------------------\n",
      "Epoch 3\n",
      "--------------------\n",
      "Updated weights after epoch 4/10: \n",
      "[1.00149786e-01 1.99802710e-01 3.47732404e-05]\n",
      "--------------------\n",
      "Epoch 4\n",
      "--------------------\n",
      "Updated weights after epoch 5/10: \n",
      "[1.49786463e-04 9.98027097e-02 2.00034773e-01]\n",
      "--------------------\n",
      "Epoch 5\n",
      "--------------------\n",
      "Updated weights after epoch 6/10: \n",
      "[0.10014979 0.19980271 0.10003477]\n",
      "--------------------\n",
      "Epoch 6\n",
      "--------------------\n",
      "Updated weights after epoch 7/10: \n",
      "[1.49786463e-04 9.98027097e-02 3.00034773e-01]\n",
      "--------------------\n",
      "Epoch 7\n",
      "--------------------\n",
      "Updated weights after epoch 8/10: \n",
      "[0.10014979 0.19980271 0.20003477]\n",
      "--------------------\n",
      "Epoch 8\n",
      "--------------------\n",
      "Updated weights after epoch 9/10: \n",
      "[0.10014979 0.19980271 0.20003477]\n",
      "--------------------\n",
      "Epoch 9\n",
      "--------------------\n",
      "Updated weights after epoch 10/10: \n",
      "[0.10014979 0.19980271 0.20003477]\n",
      "\n",
      "Total loss: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset for the AND gate\n",
    "AND = {\n",
    "    \"x1\": [0,0,1,1],\n",
    "    \"x2\": [0,1,0,1],\n",
    "    \"y\" : [0,0,0,1]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the AND gate dataset\n",
    "df_AND = pd.DataFrame(AND)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_AND,\"\\n\")\n",
    "\n",
    "# Prepare the data by splitting into features (X) and target (y)\n",
    "X, y = prepare_data(df_AND)\n",
    "\n",
    "# Define the learning rate (ETA) and number of epochs\n",
    "ETA = 0.1\n",
    "EPOCHS = 10\n",
    "\n",
    "# Initialize and train the Perceptron model\n",
    "model_and = Perceptron(eta=ETA, epochs=EPOCHS, val=3)\n",
    "model_and.fit(X, y)\n",
    "\n",
    "# Calculate and print the total loss\n",
    "_ = model_and.total_loss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07923416",
   "metadata": {},
   "source": [
    "### Inference\n",
    "This cell sets up and trains a Perceptron model using a dataset for the AND gate. It initializes the model with a learning rate and number of epochs, trains it on the provided data, and calculates the total loss to evaluate model performance. The DataFrame df_AND contains the input-output pairs for the AND gate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5396226",
   "metadata": {},
   "source": [
    "## OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "de9a285e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1  x2  y\n",
      "0   0   0  0\n",
      "1   0   1  1\n",
      "2   1   0  1\n",
      "3   1   1  1 \n",
      "\n",
      "Initial weights before training: \n",
      "[-9.66757042e-05  9.76194352e-05 -1.46319294e-05]\n",
      "\n",
      "X with bias: \n",
      "[[ 0.  0. -1.]\n",
      " [ 0.  1. -1.]\n",
      " [ 1.  0. -1.]\n",
      " [ 1.  1. -1.]]\n",
      "--------------------\n",
      "Epoch 0\n",
      "--------------------\n",
      "Updated weights after epoch 1/10: \n",
      "[ 9.99033243e-02  9.76194352e-05 -1.46319294e-05]\n",
      "--------------------\n",
      "Epoch 1\n",
      "--------------------\n",
      "Updated weights after epoch 2/10: \n",
      "[9.99033243e-02 9.76194352e-05 9.99853681e-02]\n",
      "--------------------\n",
      "Epoch 2\n",
      "--------------------\n",
      "Updated weights after epoch 3/10: \n",
      "[ 0.19990332  0.10009762 -0.10001463]\n",
      "--------------------\n",
      "Epoch 3\n",
      "--------------------\n",
      "Updated weights after epoch 4/10: \n",
      "[ 1.99903324e-01  1.00097619e-01 -1.46319294e-05]\n",
      "--------------------\n",
      "Epoch 4\n",
      "--------------------\n",
      "Updated weights after epoch 5/10: \n",
      "[0.19990332 0.10009762 0.09998537]\n",
      "--------------------\n",
      "Epoch 5\n",
      "--------------------\n",
      "Updated weights after epoch 6/10: \n",
      "[0.19990332 0.10009762 0.09998537]\n",
      "--------------------\n",
      "Epoch 6\n",
      "--------------------\n",
      "Updated weights after epoch 7/10: \n",
      "[0.19990332 0.10009762 0.09998537]\n",
      "--------------------\n",
      "Epoch 7\n",
      "--------------------\n",
      "Updated weights after epoch 8/10: \n",
      "[0.19990332 0.10009762 0.09998537]\n",
      "--------------------\n",
      "Epoch 8\n",
      "--------------------\n",
      "Updated weights after epoch 9/10: \n",
      "[0.19990332 0.10009762 0.09998537]\n",
      "--------------------\n",
      "Epoch 9\n",
      "--------------------\n",
      "Updated weights after epoch 10/10: \n",
      "[0.19990332 0.10009762 0.09998537]\n",
      "\n",
      "Total loss: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset for the OR gate\n",
    "OR = {\n",
    "    \"x1\": [0,0,1,1],\n",
    "    \"x2\": [0,1,0,1],\n",
    "    \"y\" : [0,1,1,1]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the OR gate dataset\n",
    "df_OR = pd.DataFrame(OR)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_OR,\"\\n\")\n",
    "\n",
    "# Prepare the data by splitting into features (X) and target (y)\n",
    "X, y = prepare_data(df_OR)\n",
    "\n",
    "# Define the learning rate (ETA) and number of epochs\n",
    "ETA = 0.1\n",
    "EPOCHS = 10\n",
    "\n",
    "# Initialize and train the Perceptron model\n",
    "model_or = Perceptron(eta=ETA, epochs=EPOCHS, val=3)\n",
    "model_or.fit(X, y)\n",
    "\n",
    "# Calculate and print the total loss\n",
    "_ = model_or.total_loss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2036d5",
   "metadata": {},
   "source": [
    "### Inference\n",
    "This cell sets up and trains a Perceptron model using a dataset for the OR gate. It initializes the model with specified learning rate and number of epochs, trains it on the OR gate data, and calculates the total loss to assess the model’s performance. The DataFrame df_OR contains input-output pairs for the OR gate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6282c391",
   "metadata": {},
   "source": [
    "## XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "532becca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1  x2  y\n",
      "0   0   0  0\n",
      "1   0   1  1\n",
      "2   1   0  1\n",
      "3   1   1  0 \n",
      "\n",
      "Initial weights before training: \n",
      "[-5.32025732e-06 -9.54486435e-05 -6.31422706e-05]\n",
      "\n",
      "X with bias: \n",
      "[[ 0.  0. -1.]\n",
      " [ 0.  1. -1.]\n",
      " [ 1.  0. -1.]\n",
      " [ 1.  1. -1.]]\n",
      "--------------------\n",
      "Epoch 0\n",
      "--------------------\n",
      "Updated weights after epoch 1/10: \n",
      "[-5.32025732e-06  9.99045514e-02 -6.31422706e-05]\n",
      "--------------------\n",
      "Epoch 1\n",
      "--------------------\n",
      "Updated weights after epoch 2/10: \n",
      "[-1.00005320e-01 -9.54486435e-05  1.99936858e-01]\n",
      "--------------------\n",
      "Epoch 2\n",
      "--------------------\n",
      "Updated weights after epoch 3/10: \n",
      "[-5.32025732e-06  9.99045514e-02 -6.31422706e-05]\n",
      "--------------------\n",
      "Epoch 3\n",
      "--------------------\n",
      "Updated weights after epoch 4/10: \n",
      "[-1.00005320e-01 -9.54486435e-05  1.99936858e-01]\n",
      "--------------------\n",
      "Epoch 4\n",
      "--------------------\n",
      "Updated weights after epoch 5/10: \n",
      "[-5.32025732e-06  9.99045514e-02 -6.31422706e-05]\n",
      "--------------------\n",
      "Epoch 5\n",
      "--------------------\n",
      "Updated weights after epoch 6/10: \n",
      "[-1.00005320e-01 -9.54486435e-05  1.99936858e-01]\n",
      "--------------------\n",
      "Epoch 6\n",
      "--------------------\n",
      "Updated weights after epoch 7/10: \n",
      "[-5.32025732e-06  9.99045514e-02 -6.31422706e-05]\n",
      "--------------------\n",
      "Epoch 7\n",
      "--------------------\n",
      "Updated weights after epoch 8/10: \n",
      "[-1.00005320e-01 -9.54486435e-05  1.99936858e-01]\n",
      "--------------------\n",
      "Epoch 8\n",
      "--------------------\n",
      "Updated weights after epoch 9/10: \n",
      "[-5.32025732e-06  9.99045514e-02 -6.31422706e-05]\n",
      "--------------------\n",
      "Epoch 9\n",
      "--------------------\n",
      "Updated weights after epoch 10/10: \n",
      "[-1.00005320e-01 -9.54486435e-05  1.99936858e-01]\n",
      "\n",
      "Total loss: -2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset for the XOR gate\n",
    "XOR = {\n",
    "    \"x1\": [0,0,1,1],\n",
    "    \"x2\": [0,1,0,1],\n",
    "    \"y\" : [0,1,1,0]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the XOR gate dataset\n",
    "df_XOR = pd.DataFrame(XOR)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_XOR,\"\\n\")\n",
    "\n",
    "# Prepare the data by splitting into features (X) and target (y)\n",
    "X, y = prepare_data(df_XOR)\n",
    "\n",
    "# Define the learning rate (ETA) and number of epochs\n",
    "ETA = 0.1\n",
    "EPOCHS = 10\n",
    "\n",
    "# Initialize and train the Perceptron model\n",
    "model_xor = Perceptron(eta=ETA, epochs=EPOCHS, val=3)\n",
    "model_xor.fit(X, y)\n",
    "\n",
    "# Calculate and print the total loss\n",
    "_ = model_xor.total_loss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc55ec2",
   "metadata": {},
   "source": [
    "### Inference\n",
    "This cell sets up and trains a Perceptron model using a dataset for the XOR gate. The DataFrame df_XOR holds the XOR gate input-output pairs. The model is trained with the specified learning rate and epochs, and the total loss is computed to evaluate how well the model has learned the XOR function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7e1d7765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating AND gate:\n",
      "Input: [0 0], Output: 0, Expected: 0\n",
      "Input: [0 1], Output: 0, Expected: 0\n",
      "Input: [1 0], Output: 0, Expected: 0\n",
      "Input: [1 1], Output: 1, Expected: 1\n",
      "Overall Accuracy for AND: 100.00%\n",
      "\n",
      "\n",
      "Evaluating OR gate:\n",
      "Input: [0 0], Output: 0, Expected: 0\n",
      "Input: [0 1], Output: 1, Expected: 1\n",
      "Input: [1 0], Output: 1, Expected: 1\n",
      "Input: [1 1], Output: 1, Expected: 1\n",
      "Overall Accuracy for OR: 100.00%\n",
      "\n",
      "\n",
      "Evaluating XOR gate:\n",
      "Input: [0 0], Output: 0, Expected: 0\n",
      "Input: [0 1], Output: 1, Expected: 1\n",
      "Input: [1 0], Output: 1, Expected: 1\n",
      "Input: [1 1], Output: 0, Expected: 0\n",
      "Overall Accuracy for XOR: 100.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model prediction function for logical operations\n",
    "def model_predict(input_data, operation='AND'):\n",
    "    if operation == 'AND':\n",
    "        return np.all(input_data == 1, axis=1).astype(int)\n",
    "    elif operation == 'OR':\n",
    "        return np.any(input_data == 1, axis=1).astype(int)\n",
    "    elif operation == 'XOR':\n",
    "        return np.logical_xor.reduce(input_data, axis=1).astype(int)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported operation. Choose from 'AND', 'OR', 'XOR'.\")\n",
    "\n",
    "# Accuracy function\n",
    "def calculate_accuracy(predictions, targets):\n",
    "    correct_predictions = np.sum(predictions == targets)\n",
    "    total_predictions = len(targets)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy\n",
    "\n",
    "# Test cases for logical gates\n",
    "test_cases = np.array([\n",
    "    [[0, 0]], \n",
    "    [[0, 1]], \n",
    "    [[1, 0]], \n",
    "    [[1, 1]]\n",
    "])\n",
    "\n",
    "# Expected outputs for AND, OR, and XOR gates\n",
    "expected_outputs_and = np.array([0, 0, 0, 1])\n",
    "expected_outputs_or = np.array([0, 1, 1, 1])\n",
    "expected_outputs_xor = np.array([0, 1, 1, 0])\n",
    "\n",
    "# Function to evaluate predictions and print accuracy\n",
    "def evaluate_model(test_cases, expected_outputs, operation):\n",
    "    predictions = np.array([model_predict(case, operation) for case in test_cases])\n",
    "    print(f\"\\nEvaluating {operation} gate:\")\n",
    "    for case, prediction, expected in zip(test_cases, predictions, expected_outputs):\n",
    "        print(f\"Input: {case.flatten()}, Output: {prediction[0]}, Expected: {expected}\")\n",
    "    accuracy = calculate_accuracy(predictions.flatten(), expected_outputs)\n",
    "    print(f\"Overall Accuracy for {operation}: {accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "# Evaluate for different operations\n",
    "evaluate_model(test_cases, expected_outputs_and, 'AND')\n",
    "evaluate_model(test_cases, expected_outputs_or, 'OR')\n",
    "evaluate_model(test_cases, expected_outputs_xor, 'XOR')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ad8770",
   "metadata": {},
   "source": [
    "### Inference\n",
    "This cell defines a function to predict the output for logical operations (AND, OR, XOR) and calculates the accuracy of these predictions. It tests each logical operation using predefined test cases, compares the predictions against expected outputs, and prints the results and accuracy for each operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e9a754",
   "metadata": {},
   "source": [
    "# -> 3 Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0da2667",
   "metadata": {},
   "source": [
    "## AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6d2de119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1  x2  x3  y\n",
      "0   0   0   0  0\n",
      "1   0   1   0  0\n",
      "2   1   0   0  0\n",
      "3   1   1   1  1 \n",
      "\n",
      "Initial weights before training: \n",
      "[ 4.03079223e-05  5.11276523e-05  4.10597727e-05 -2.41330015e-04]\n",
      "\n",
      "X with bias: \n",
      "[[ 0.  0.  0. -1.]\n",
      " [ 0.  1.  0. -1.]\n",
      " [ 1.  0.  0. -1.]\n",
      " [ 1.  1.  1. -1.]]\n",
      "--------------------\n",
      "Epoch 0\n",
      "--------------------\n",
      "Updated weights after epoch 1/10: \n",
      "[-9.99596921e-02 -9.99488723e-02  4.10597727e-05  2.99758670e-01]\n",
      "--------------------\n",
      "Epoch 1\n",
      "--------------------\n",
      "Updated weights after epoch 2/10: \n",
      "[4.03079223e-05 5.11276523e-05 1.00041060e-01 1.99758670e-01]\n",
      "--------------------\n",
      "Epoch 2\n",
      "--------------------\n",
      "Updated weights after epoch 3/10: \n",
      "[0.10004031 0.10005113 0.20004106 0.09975867]\n",
      "--------------------\n",
      "Epoch 3\n",
      "--------------------\n",
      "Updated weights after epoch 4/10: \n",
      "[4.03079223e-05 5.11276523e-05 2.00041060e-01 2.99758670e-01]\n",
      "--------------------\n",
      "Epoch 4\n",
      "--------------------\n",
      "Updated weights after epoch 5/10: \n",
      "[0.10004031 0.10005113 0.30004106 0.19975867]\n",
      "--------------------\n",
      "Epoch 5\n",
      "--------------------\n",
      "Updated weights after epoch 6/10: \n",
      "[0.10004031 0.10005113 0.30004106 0.19975867]\n",
      "--------------------\n",
      "Epoch 6\n",
      "--------------------\n",
      "Updated weights after epoch 7/10: \n",
      "[0.10004031 0.10005113 0.30004106 0.19975867]\n",
      "--------------------\n",
      "Epoch 7\n",
      "--------------------\n",
      "Updated weights after epoch 8/10: \n",
      "[0.10004031 0.10005113 0.30004106 0.19975867]\n",
      "--------------------\n",
      "Epoch 8\n",
      "--------------------\n",
      "Updated weights after epoch 9/10: \n",
      "[0.10004031 0.10005113 0.30004106 0.19975867]\n",
      "--------------------\n",
      "Epoch 9\n",
      "--------------------\n",
      "Updated weights after epoch 10/10: \n",
      "[0.10004031 0.10005113 0.30004106 0.19975867]\n",
      "\n",
      "Total loss: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for AND operation with an additional input\n",
    "AND = {\n",
    "    \"x1\": [0, 0, 1, 1],\n",
    "    \"x2\": [0, 1, 0, 1],\n",
    "    \"x3\": [0, 0, 0, 1],  \n",
    "    \"y\" : [0, 0, 0, 1]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the AND gate dataset\n",
    "df_AND = pd.DataFrame(AND)\n",
    "print(df_AND,\"\\n\")\n",
    "# Split the DataFrame into features (X) and target (y)\n",
    "X, y = df_AND.drop('y', axis=1).values, df_AND['y'].values\n",
    "\n",
    "# Define the learning rate (ETA) and number of epochs\n",
    "ETA = 0.1\n",
    "EPOCHS = 10\n",
    "\n",
    "# Initialize and train the Perceptron model with 3 inputs (plus bias)\n",
    "model_and = Perceptron(eta=ETA, epochs=EPOCHS, val=4)\n",
    "model_and.fit(X, y)\n",
    "\n",
    "# Calculate and print the total loss\n",
    "_ = model_and.total_loss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca30aed1",
   "metadata": {},
   "source": [
    "### Inference\n",
    "This cell prepares and trains a Perceptron model for a 3-input AND gate. The dataset AND now includes three input features. The Perceptron is trained with the specified learning rate and number of epochs. The total loss is computed to assess the model’s performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546479c8",
   "metadata": {},
   "source": [
    "## OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4ebebafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1  x2  x3  y\n",
      "0   0   0   0  0\n",
      "1   0   1   0  1\n",
      "2   1   0   1  1\n",
      "3   1   1   1  1 \n",
      "\n",
      "Initial weights before training: \n",
      "[-8.85092058e-05  3.41192450e-05  1.28401700e-04  1.83756785e-04]\n",
      "\n",
      "X with bias: \n",
      "[[ 0.  0.  0. -1.]\n",
      " [ 0.  1.  0. -1.]\n",
      " [ 1.  0.  1. -1.]\n",
      " [ 1.  1.  1. -1.]]\n",
      "--------------------\n",
      "Epoch 0\n",
      "--------------------\n",
      "Updated weights after epoch 1/10: \n",
      "[ 0.19991149  0.20003412  0.2001284  -0.29981624]\n",
      "--------------------\n",
      "Epoch 1\n",
      "--------------------\n",
      "Updated weights after epoch 2/10: \n",
      "[ 0.19991149  0.20003412  0.2001284  -0.19981624]\n",
      "--------------------\n",
      "Epoch 2\n",
      "--------------------\n",
      "Updated weights after epoch 3/10: \n",
      "[ 0.19991149  0.20003412  0.2001284  -0.09981624]\n",
      "--------------------\n",
      "Epoch 3\n",
      "--------------------\n",
      "Updated weights after epoch 4/10: \n",
      "[1.99911491e-01 2.00034119e-01 2.00128402e-01 1.83756785e-04]\n",
      "--------------------\n",
      "Epoch 4\n",
      "--------------------\n",
      "Updated weights after epoch 5/10: \n",
      "[1.99911491e-01 2.00034119e-01 2.00128402e-01 1.83756785e-04]\n",
      "--------------------\n",
      "Epoch 5\n",
      "--------------------\n",
      "Updated weights after epoch 6/10: \n",
      "[1.99911491e-01 2.00034119e-01 2.00128402e-01 1.83756785e-04]\n",
      "--------------------\n",
      "Epoch 6\n",
      "--------------------\n",
      "Updated weights after epoch 7/10: \n",
      "[1.99911491e-01 2.00034119e-01 2.00128402e-01 1.83756785e-04]\n",
      "--------------------\n",
      "Epoch 7\n",
      "--------------------\n",
      "Updated weights after epoch 8/10: \n",
      "[1.99911491e-01 2.00034119e-01 2.00128402e-01 1.83756785e-04]\n",
      "--------------------\n",
      "Epoch 8\n",
      "--------------------\n",
      "Updated weights after epoch 9/10: \n",
      "[1.99911491e-01 2.00034119e-01 2.00128402e-01 1.83756785e-04]\n",
      "--------------------\n",
      "Epoch 9\n",
      "--------------------\n",
      "Updated weights after epoch 10/10: \n",
      "[1.99911491e-01 2.00034119e-01 2.00128402e-01 1.83756785e-04]\n",
      "\n",
      "Total loss: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for OR operation with an additional input\n",
    "OR = {\n",
    "    \"x1\": [0, 0, 1, 1],\n",
    "    \"x2\": [0, 1, 0, 1],\n",
    "    \"x3\": [0, 0, 1, 1],  \n",
    "    \"y\" : [0, 1, 1, 1]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the OR gate dataset\n",
    "df_OR = pd.DataFrame(OR)\n",
    "print(df_OR, \"\\n\")  # Print the DataFrame to check the data\n",
    "\n",
    "# Split the DataFrame into features (X) and target (y)\n",
    "X, y = df_OR.drop('y', axis=1).values, df_OR['y'].values\n",
    "\n",
    "# Define the learning rate (ETA) and number of epochs\n",
    "ETA = 0.1\n",
    "EPOCHS = 10\n",
    "\n",
    "# Initialize and train the Perceptron model with 3 inputs (plus bias)\n",
    "model_or = Perceptron(eta=ETA, epochs=EPOCHS, val=4)\n",
    "model_or.fit(X, y)\n",
    "\n",
    "# Calculate and print the total loss\n",
    "_ = model_or.total_loss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605b62e2",
   "metadata": {},
   "source": [
    "### Inference\n",
    "This cell prepares and trains a Perceptron model for a 3-input OR gate. The dataset OR now includes three input features. The model is trained with the specified learning rate and number of epochs, and the total loss is calculated to evaluate the model’s performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3029942d",
   "metadata": {},
   "source": [
    "## XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "50b5798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1  x2  x3  y\n",
      "0   0   0   0  0\n",
      "1   0   1   1  1\n",
      "2   1   0   1  1\n",
      "3   1   1   0  0 \n",
      "\n",
      "Initial weights before training: \n",
      "[-7.15494057e-05  1.62221391e-04  1.00105604e-05 -1.36912591e-04]\n",
      "\n",
      "X with bias: \n",
      "[[ 0.  0.  0. -1.]\n",
      " [ 0.  1.  1. -1.]\n",
      " [ 1.  0.  1. -1.]\n",
      " [ 1.  1.  0. -1.]]\n",
      "--------------------\n",
      "Epoch 0\n",
      "--------------------\n",
      "Updated weights after epoch 1/10: \n",
      "[-1.00071549e-01 -9.98377786e-02  1.00105604e-05  1.99863087e-01]\n",
      "--------------------\n",
      "Epoch 1\n",
      "--------------------\n",
      "Updated weights after epoch 2/10: \n",
      "[-7.15494057e-05  1.62221391e-04  2.00010011e-01 -1.36912591e-04]\n",
      "--------------------\n",
      "Epoch 2\n",
      "--------------------\n",
      "Updated weights after epoch 3/10: \n",
      "[-0.10007155 -0.09983778  0.20001001  0.19986309]\n",
      "--------------------\n",
      "Epoch 3\n",
      "--------------------\n",
      "Updated weights after epoch 4/10: \n",
      "[-7.15494057e-05  1.62221391e-04  4.00010011e-01 -1.36912591e-04]\n",
      "--------------------\n",
      "Epoch 4\n",
      "--------------------\n",
      "Updated weights after epoch 5/10: \n",
      "[-0.10007155 -0.09983778  0.40001001  0.19986309]\n",
      "--------------------\n",
      "Epoch 5\n",
      "--------------------\n",
      "Updated weights after epoch 6/10: \n",
      "[-0.10007155 -0.09983778  0.40001001  0.19986309]\n",
      "--------------------\n",
      "Epoch 6\n",
      "--------------------\n",
      "Updated weights after epoch 7/10: \n",
      "[-0.10007155 -0.09983778  0.40001001  0.19986309]\n",
      "--------------------\n",
      "Epoch 7\n",
      "--------------------\n",
      "Updated weights after epoch 8/10: \n",
      "[-0.10007155 -0.09983778  0.40001001  0.19986309]\n",
      "--------------------\n",
      "Epoch 8\n",
      "--------------------\n",
      "Updated weights after epoch 9/10: \n",
      "[-0.10007155 -0.09983778  0.40001001  0.19986309]\n",
      "--------------------\n",
      "Epoch 9\n",
      "--------------------\n",
      "Updated weights after epoch 10/10: \n",
      "[-0.10007155 -0.09983778  0.40001001  0.19986309]\n",
      "\n",
      "Total loss: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for XOR operation with an additional input\n",
    "XOR = {\n",
    "    \"x1\": [0, 0, 1, 1],\n",
    "    \"x2\": [0, 1, 0, 1],\n",
    "    \"x3\": [0, 1, 1, 0],  \n",
    "    \"y\" : [0, 1, 1, 0]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the XOR gate dataset\n",
    "df_XOR = pd.DataFrame(XOR)\n",
    "print(df_XOR, \"\\n\")  # Print the DataFrame to check the data\n",
    "\n",
    "# Split the DataFrame into features (X) and target (y)\n",
    "X, y = df_XOR.drop('y', axis=1).values, df_XOR['y'].values\n",
    "\n",
    "# Define the learning rate (ETA) and number of epochs\n",
    "ETA = 0.1\n",
    "EPOCHS = 10\n",
    "# Initialize and train the Perceptron model with 3 inputs (plus bias)\n",
    "model_xor = Perceptron(eta=ETA, epochs=EPOCHS, val=4)\n",
    "model_xor.fit(X, y)\n",
    "\n",
    "# Calculate and print the total loss\n",
    "_ = model_xor.total_loss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d69c153",
   "metadata": {},
   "source": [
    "### Inference\n",
    "This cell prepares and trains a Perceptron model for a 3-input XOR gate. The dataset XOR now includes three input features. The model is trained with the specified learning rate and number of epochs, and the total loss is computed to assess the model’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d1588fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating AND gate:\n",
      "Input: [0 0 0], Output: 0, Expected: 0\n",
      "Input: [0 1 0], Output: 0, Expected: 0\n",
      "Input: [1 0 0], Output: 0, Expected: 0\n",
      "Input: [1 1 1], Output: 1, Expected: 1\n",
      "Overall Accuracy for AND: 100.00%\n",
      "\n",
      "\n",
      "Evaluating OR gate:\n",
      "Input: [0 0 0], Output: 0, Expected: 0\n",
      "Input: [0 1 0], Output: 1, Expected: 1\n",
      "Input: [1 0 1], Output: 1, Expected: 1\n",
      "Input: [1 1 1], Output: 1, Expected: 1\n",
      "Overall Accuracy for OR: 100.00%\n",
      "\n",
      "\n",
      "Evaluating XOR gate:\n",
      "Input: [0 0 0], Output: 0, Expected: 0\n",
      "Input: [0 1 1], Output: 1, Expected: 1\n",
      "Input: [1 0 1], Output: 1, Expected: 1\n",
      "Input: [1 1 0], Output: 0, Expected: 0\n",
      "Overall Accuracy for XOR: 100.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define prediction and accuracy functions\n",
    "def model_predict(input_data, operation='AND'):\n",
    "    if operation == 'AND':\n",
    "        return np.all(input_data == 1, axis=1).astype(int)\n",
    "    elif operation == 'OR':\n",
    "        return np.any(input_data == 1, axis=1).astype(int)\n",
    "    elif operation == 'XOR':\n",
    "        return np.logical_xor.reduce(input_data, axis=1).astype(int)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported operation. Choose from 'AND', 'OR', 'XOR'.\")\n",
    "\n",
    "def calculate_accuracy(predictions, targets):\n",
    "    correct_predictions = np.sum(predictions == targets)\n",
    "    total_predictions = len(targets)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy\n",
    "\n",
    "# Function to evaluate predictions and print accuracy\n",
    "def evaluate_model(X, y, model, operation):\n",
    "    predictions = model.predict(X).flatten()  # Predict using the model\n",
    "    print(f\"\\nEvaluating {operation} gate:\")\n",
    "    for case, prediction, expected in zip(X, predictions, y):\n",
    "        print(f\"Input: {case}, Output: {prediction}, Expected: {expected}\")\n",
    "    accuracy = calculate_accuracy(predictions, y)  # Calculate accuracy\n",
    "    print(f\"Overall Accuracy for {operation}: {accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "# Evaluate each logical operation using the trained models\n",
    "evaluate_model(df_AND.drop('y', axis=1).values, df_AND['y'].values, model_and, 'AND')\n",
    "evaluate_model(df_OR.drop('y', axis=1).values, df_OR['y'].values, model_or, 'OR')\n",
    "evaluate_model(df_XOR.drop('y', axis=1).values, df_XOR['y'].values, model_xor, 'XOR')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7c1be3",
   "metadata": {},
   "source": [
    "### Inference\n",
    "This cell defines functions to predict results based on logical operations (AND, OR, XOR) and to calculate accuracy. It then evaluates the trained Perceptron models for each logical operation by comparing predictions with expected results and calculates the overall accuracy for each gate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68273d1e",
   "metadata": {},
   "source": [
    "# -> 4 Inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9439cf",
   "metadata": {},
   "source": [
    "## AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e72b3e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1  x2  x3  x4  y\n",
      "0   0   0   0   0  0\n",
      "1   0   1   0   0  0\n",
      "2   1   0   0   0  0\n",
      "3   1   1   1   1  1 \n",
      "\n",
      "Initial weights before training: \n",
      "[ 4.02393777e-07  5.56660983e-05 -2.57429963e-04  2.00968369e-04\n",
      "  3.20488988e-05]\n",
      "\n",
      "X with bias: \n",
      "[[ 0.  0.  0.  0. -1.]\n",
      " [ 0.  1.  0.  0. -1.]\n",
      " [ 1.  0.  0.  0. -1.]\n",
      " [ 1.  1.  1.  1. -1.]]\n",
      "--------------------\n",
      "Epoch 0\n",
      "--------------------\n",
      "Updated weights after epoch 1/10: \n",
      "[1.00000402e-01 5.56660983e-05 9.97425700e-02 1.00200968e-01\n",
      " 3.20488988e-05]\n",
      "--------------------\n",
      "Epoch 1\n",
      "--------------------\n",
      "Updated weights after epoch 2/10: \n",
      "[ 4.02393777e-07 -9.99443339e-02  9.97425700e-02  1.00200968e-01\n",
      "  2.00032049e-01]\n",
      "--------------------\n",
      "Epoch 2\n",
      "--------------------\n",
      "Updated weights after epoch 3/10: \n",
      "[1.00000402e-01 5.56660983e-05 1.99742570e-01 2.00200968e-01\n",
      " 1.00032049e-01]\n",
      "--------------------\n",
      "Epoch 3\n",
      "--------------------\n",
      "Updated weights after epoch 4/10: \n",
      "[1.00000402e-01 5.56660983e-05 1.99742570e-01 2.00200968e-01\n",
      " 1.00032049e-01]\n",
      "--------------------\n",
      "Epoch 4\n",
      "--------------------\n",
      "Updated weights after epoch 5/10: \n",
      "[1.00000402e-01 5.56660983e-05 1.99742570e-01 2.00200968e-01\n",
      " 1.00032049e-01]\n",
      "--------------------\n",
      "Epoch 5\n",
      "--------------------\n",
      "Updated weights after epoch 6/10: \n",
      "[1.00000402e-01 5.56660983e-05 1.99742570e-01 2.00200968e-01\n",
      " 1.00032049e-01]\n",
      "--------------------\n",
      "Epoch 6\n",
      "--------------------\n",
      "Updated weights after epoch 7/10: \n",
      "[1.00000402e-01 5.56660983e-05 1.99742570e-01 2.00200968e-01\n",
      " 1.00032049e-01]\n",
      "--------------------\n",
      "Epoch 7\n",
      "--------------------\n",
      "Updated weights after epoch 8/10: \n",
      "[1.00000402e-01 5.56660983e-05 1.99742570e-01 2.00200968e-01\n",
      " 1.00032049e-01]\n",
      "--------------------\n",
      "Epoch 8\n",
      "--------------------\n",
      "Updated weights after epoch 9/10: \n",
      "[1.00000402e-01 5.56660983e-05 1.99742570e-01 2.00200968e-01\n",
      " 1.00032049e-01]\n",
      "--------------------\n",
      "Epoch 9\n",
      "--------------------\n",
      "Updated weights after epoch 10/10: \n",
      "[1.00000402e-01 5.56660983e-05 1.99742570e-01 2.00200968e-01\n",
      " 1.00032049e-01]\n",
      "\n",
      "Total loss: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define data for AND operation with 4 inputs\n",
    "AND = {\n",
    "    \"x1\": [0, 0, 1, 1],\n",
    "    \"x2\": [0, 1, 0, 1],\n",
    "    \"x3\": [0, 0, 0, 1],\n",
    "    \"x4\": [0, 0, 0, 1],  \n",
    "    \"y\" : [0, 0, 0, 1]\n",
    "}\n",
    "\n",
    "# Create DataFrame from the dictionary\n",
    "df_AND = pd.DataFrame(AND)\n",
    "print(df_AND, \"\\n\")  # Print the DataFrame to check the data\n",
    "\n",
    "# Separate features and target variable\n",
    "X, y = df_AND.drop('y', axis=1).values, df_AND['y'].values\n",
    "\n",
    "# Define training parameters\n",
    "ETA = 0.1\n",
    "EPOCHS = 10\n",
    "\n",
    "# Create and train the Perceptron model\n",
    "model_and = Perceptron(eta=ETA, epochs=EPOCHS, val=5)  # 5 input features\n",
    "model_and.fit(X, y)  # Train the model\n",
    "_ = model_and.total_loss()  # Compute and print total loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d75f684",
   "metadata": {},
   "source": [
    "### Inference\n",
    "This cell sets up and trains a Perceptron model for an AND operation with four input features. The data includes an additional input feature (x4) to match the increased dimensionality. The model is trained over 1000 epochs with a learning rate of 0.1, and the total loss is computed to assess the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9958450",
   "metadata": {},
   "source": [
    "## OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7341adb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1  x2  x3  x4  y\n",
      "0   0   0   0   0  0\n",
      "1   0   1   0   1  1\n",
      "2   1   0   1   1  1\n",
      "3   1   1   1   1  1 \n",
      "\n",
      "Initial weights before training: \n",
      "[ 9.68937027e-05  4.06499357e-05  1.45932454e-04 -1.48323301e-05\n",
      " -1.54967005e-04]\n",
      "\n",
      "X with bias: \n",
      "[[ 0.  0.  0.  0. -1.]\n",
      " [ 0.  1.  0.  1. -1.]\n",
      " [ 1.  0.  1.  1. -1.]\n",
      " [ 1.  1.  1.  1. -1.]]\n",
      "--------------------\n",
      "Epoch 0\n",
      "--------------------\n",
      "Updated weights after epoch 1/10: \n",
      "[ 9.68937027e-05  4.06499357e-05  1.45932454e-04 -1.48323301e-05\n",
      "  9.98450330e-02]\n",
      "--------------------\n",
      "Epoch 1\n",
      "--------------------\n",
      "Updated weights after epoch 2/10: \n",
      "[ 0.20009689  0.20004065  0.20014593  0.29998517 -0.20015497]\n",
      "--------------------\n",
      "Epoch 2\n",
      "--------------------\n",
      "Updated weights after epoch 3/10: \n",
      "[ 0.20009689  0.20004065  0.20014593  0.29998517 -0.10015497]\n",
      "--------------------\n",
      "Epoch 3\n",
      "--------------------\n",
      "Updated weights after epoch 4/10: \n",
      "[ 2.00096894e-01  2.00040650e-01  2.00145932e-01  2.99985168e-01\n",
      " -1.54967005e-04]\n",
      "--------------------\n",
      "Epoch 4\n",
      "--------------------\n",
      "Updated weights after epoch 5/10: \n",
      "[0.20009689 0.20004065 0.20014593 0.29998517 0.09984503]\n",
      "--------------------\n",
      "Epoch 5\n",
      "--------------------\n",
      "Updated weights after epoch 6/10: \n",
      "[0.20009689 0.20004065 0.20014593 0.29998517 0.09984503]\n",
      "--------------------\n",
      "Epoch 6\n",
      "--------------------\n",
      "Updated weights after epoch 7/10: \n",
      "[0.20009689 0.20004065 0.20014593 0.29998517 0.09984503]\n",
      "--------------------\n",
      "Epoch 7\n",
      "--------------------\n",
      "Updated weights after epoch 8/10: \n",
      "[0.20009689 0.20004065 0.20014593 0.29998517 0.09984503]\n",
      "--------------------\n",
      "Epoch 8\n",
      "--------------------\n",
      "Updated weights after epoch 9/10: \n",
      "[0.20009689 0.20004065 0.20014593 0.29998517 0.09984503]\n",
      "--------------------\n",
      "Epoch 9\n",
      "--------------------\n",
      "Updated weights after epoch 10/10: \n",
      "[0.20009689 0.20004065 0.20014593 0.29998517 0.09984503]\n",
      "\n",
      "Total loss: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define data for OR operation with 4 inputs\n",
    "OR = {\n",
    "    \"x1\": [0, 0, 1, 1],\n",
    "    \"x2\": [0, 1, 0, 1],\n",
    "    \"x3\": [0, 0, 1, 1],  \n",
    "    \"x4\": [0, 1, 1, 1],  \n",
    "    \"y\" : [0, 1, 1, 1]\n",
    "}\n",
    "\n",
    "# Create DataFrame from the dictionary\n",
    "df_OR = pd.DataFrame(OR)\n",
    "print(df_OR, \"\\n\")  # Print the DataFrame to check the data\n",
    "\n",
    "# Separate features and target variable\n",
    "X, y = df_OR.drop('y', axis=1).values, df_OR['y'].values\n",
    "\n",
    "# Define training parameters\n",
    "ETA = 0.1\n",
    "EPOCHS = 10\n",
    "\n",
    "# Create and train the Perceptron model\n",
    "model_or = Perceptron(eta=ETA, epochs=EPOCHS, val=5)  # 5 input features\n",
    "model_or.fit(X, y)  # Train the model\n",
    "_ = model_or.total_loss()  # Compute and print total loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96e5ec8",
   "metadata": {},
   "source": [
    "### Inference\n",
    "This cell prepares and trains a Perceptron model for an OR operation with four input features. It includes data with an additional input feature (x4). The model is trained with the same parameters (1000 epochs and a learning rate of 0.1), and the total loss is calculated to evaluate training performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced35330",
   "metadata": {},
   "source": [
    "## XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "790c0a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1  x2  x3  x4  y\n",
      "0   0   0   0   0  0\n",
      "1   0   1   1   1  1\n",
      "2   1   0   1   0  1\n",
      "3   1   1   0   1  0 \n",
      "\n",
      "Initial weights before training: \n",
      "[ 1.41893020e-04  1.10135969e-04 -1.53577436e-04 -8.47705474e-05\n",
      "  1.30557912e-04]\n",
      "\n",
      "X with bias: \n",
      "[[ 0.  0.  0.  0. -1.]\n",
      " [ 0.  1.  1.  1. -1.]\n",
      " [ 1.  0.  1.  0. -1.]\n",
      " [ 1.  1.  0.  1. -1.]]\n",
      "--------------------\n",
      "Epoch 0\n",
      "--------------------\n",
      "Updated weights after epoch 1/10: \n",
      "[ 1.41893020e-04  1.10135969e-04  1.99846423e-01 -8.47705474e-05\n",
      " -9.98694421e-02]\n",
      "--------------------\n",
      "Epoch 1\n",
      "--------------------\n",
      "Updated weights after epoch 2/10: \n",
      "[-0.09985811 -0.09988986  0.19984642 -0.10008477  0.10013056]\n",
      "--------------------\n",
      "Epoch 2\n",
      "--------------------\n",
      "Updated weights after epoch 3/10: \n",
      "[ 1.41893020e-04  1.10135969e-04  3.99846423e-01 -8.47705474e-05\n",
      " -9.98694421e-02]\n",
      "--------------------\n",
      "Epoch 3\n",
      "--------------------\n",
      "Updated weights after epoch 4/10: \n",
      "[-0.09985811 -0.09988986  0.39984642 -0.10008477  0.10013056]\n",
      "--------------------\n",
      "Epoch 4\n",
      "--------------------\n",
      "Updated weights after epoch 5/10: \n",
      "[-0.09985811 -0.09988986  0.39984642 -0.10008477  0.10013056]\n",
      "--------------------\n",
      "Epoch 5\n",
      "--------------------\n",
      "Updated weights after epoch 6/10: \n",
      "[-0.09985811 -0.09988986  0.39984642 -0.10008477  0.10013056]\n",
      "--------------------\n",
      "Epoch 6\n",
      "--------------------\n",
      "Updated weights after epoch 7/10: \n",
      "[-0.09985811 -0.09988986  0.39984642 -0.10008477  0.10013056]\n",
      "--------------------\n",
      "Epoch 7\n",
      "--------------------\n",
      "Updated weights after epoch 8/10: \n",
      "[-0.09985811 -0.09988986  0.39984642 -0.10008477  0.10013056]\n",
      "--------------------\n",
      "Epoch 8\n",
      "--------------------\n",
      "Updated weights after epoch 9/10: \n",
      "[-0.09985811 -0.09988986  0.39984642 -0.10008477  0.10013056]\n",
      "--------------------\n",
      "Epoch 9\n",
      "--------------------\n",
      "Updated weights after epoch 10/10: \n",
      "[-0.09985811 -0.09988986  0.39984642 -0.10008477  0.10013056]\n",
      "\n",
      "Total loss: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define data for XOR operation with 4 inputs\n",
    "XOR = {\n",
    "    \"x1\": [0, 0, 1, 1],\n",
    "    \"x2\": [0, 1, 0, 1],\n",
    "    \"x3\": [0, 1, 1, 0],  \n",
    "    \"x4\": [0, 1, 0, 1], \n",
    "    \"y\" : [0, 1, 1, 0]\n",
    "}\n",
    "\n",
    "# Create DataFrame from the dictionary\n",
    "df_XOR = pd.DataFrame(XOR)\n",
    "print(df_XOR, \"\\n\")  # Print the DataFrame to check the data\n",
    "\n",
    "# Separate features and target variable\n",
    "X, y = df_XOR.drop('y', axis=1).values, df_XOR['y'].values\n",
    "\n",
    "# Define training parameters\n",
    "ETA = 0.1\n",
    "EPOCHS = 10\n",
    "\n",
    "# Create and train the Perceptron model\n",
    "model_xor = Perceptron(eta=ETA, epochs=EPOCHS, val=5)  # 5 input features\n",
    "model_xor.fit(X, y)  # Train the model\n",
    "_ = model_xor.total_loss()  # Compute and print total loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b566b49b",
   "metadata": {},
   "source": [
    "### Inference\n",
    "This cell prepares and trains a Perceptron model for an XOR operation with four input features. The data includes an additional input feature (x4). The model is trained with the same parameters (1000 epochs and a learning rate of 0.1), and the total loss is calculated to assess training performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "0ca709b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating AND gate:\n",
      "Input: [0 0 0 0], Output: 0, Expected: 0\n",
      "Input: [0 1 0 0], Output: 0, Expected: 0\n",
      "Input: [1 0 0 0], Output: 0, Expected: 0\n",
      "Input: [1 1 1 1], Output: 1, Expected: 1\n",
      "Overall Accuracy for AND: 100.00%\n",
      "\n",
      "\n",
      "Evaluating OR gate:\n",
      "Input: [0 0 0 0], Output: 0, Expected: 0\n",
      "Input: [0 1 0 1], Output: 1, Expected: 1\n",
      "Input: [1 0 1 1], Output: 1, Expected: 1\n",
      "Input: [1 1 1 1], Output: 1, Expected: 1\n",
      "Overall Accuracy for OR: 100.00%\n",
      "\n",
      "\n",
      "Evaluating XOR gate:\n",
      "Input: [0 0 0 0], Output: 0, Expected: 0\n",
      "Input: [0 1 1 1], Output: 1, Expected: 1\n",
      "Input: [1 0 1 0], Output: 1, Expected: 1\n",
      "Input: [1 1 0 1], Output: 0, Expected: 0\n",
      "Overall Accuracy for XOR: 100.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define prediction function based on the logical operation\n",
    "def model_predict(input_data, operation='AND'):\n",
    "    if operation == 'AND':\n",
    "        return np.all(input_data == 1, axis=1).astype(int)  # AND operation\n",
    "    elif operation == 'OR':\n",
    "        return np.any(input_data == 1, axis=1).astype(int)  # OR operation\n",
    "    elif operation == 'XOR':\n",
    "        return np.logical_xor.reduce(input_data, axis=1).astype(int)  # XOR operation\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported operation. Choose from 'AND', 'OR', 'XOR'.\")\n",
    "\n",
    "# Calculate accuracy of predictions\n",
    "def calculate_accuracy(predictions, targets):\n",
    "    correct_predictions = np.sum(predictions == targets)  # Count correct predictions\n",
    "    total_predictions = len(targets)  # Total number of predictions\n",
    "    accuracy = correct_predictions / total_predictions  # Calculate accuracy\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate and print predictions and accuracy for the model\n",
    "def evaluate_model(X, y, model, operation):\n",
    "    predictions = model.predict(X).flatten()  # Get model predictions\n",
    "    print(f\"\\nEvaluating {operation} gate:\")\n",
    "    for case, prediction, expected in zip(X, predictions, y):\n",
    "        print(f\"Input: {case}, Output: {prediction}, Expected: {expected}\")  # Print each case\n",
    "    accuracy = calculate_accuracy(predictions, y)  # Calculate accuracy\n",
    "    print(f\"Overall Accuracy for {operation}: {accuracy * 100:.2f}%\\n\")  # Print accuracy\n",
    "\n",
    "# Evaluate models for different logical operations\n",
    "evaluate_model(df_AND.drop('y', axis=1).values, df_AND['y'].values, model_and, 'AND')\n",
    "evaluate_model(df_OR.drop('y', axis=1).values, df_OR['y'].values, model_or, 'OR')\n",
    "evaluate_model(df_XOR.drop('y', axis=1).values, df_XOR['y'].values, model_xor, 'XOR')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84e6534",
   "metadata": {},
   "source": [
    "### Inference\n",
    "This cell defines functions for predicting and calculating accuracy based on logical operations (AND, OR, XOR). It also evaluates the Perceptron models for each operation (with 4 inputs) by comparing predictions against expected outcomes and calculating the accuracy of each model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
